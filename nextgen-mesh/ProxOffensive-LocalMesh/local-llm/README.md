# Local LLM Cluster

This directory will contain:

- Model choices and configuration
- Scripts to start/stop local inference servers (Ollama, LM Studio, etc.)
- Routing helpers for local vs cloud tasks
